psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (12.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
xim = np.arange(-40, 40, 1.0)  # assume image coords are centered on sources
n_sources = 5  # 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 21, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)
#plt.xlim(-100, 100)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (12.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
xim = np.arange(-40, 40, 1.0)  # assume image coords are centered on sources
n_sources = 5  # 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 21, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)
#plt.xlim(-100, 100)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (12.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
xim = np.arange(-40, 40, 1.0)  # assume image coords are centered on sources
n_sources = 5  # 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 21, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)
#plt.xlim(-100, 100)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 21, 1.)  # This is the axis that we will compute the conv. kernels on
print x
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 22, 1.)  # This is the axis that we will compute the conv. kernels on
print x
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (12.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 22, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)
#plt.xlim(-100, 100)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)
plt.xlim(-100, 100)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
plt.xlim(-100, 100)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)
ax1.xaxis?
ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)
ax1.xaxis(-100, 100)
ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 22, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 22, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns
basis /= basis.sum(1)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T
basis2 /= basis2.sum(1)

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 22, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns
basis /= basis.sum(0)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T
basis2 /= basis2.sum(0)

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-21, 22, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
#%%timeit 
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
print b.shape, M.shape
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
#%%timeit 
basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 0.75   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-15, 16, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-15, 16, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2)
?plt.subplots
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.show()
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-100, 100)
plt.show()
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
#ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
print pars; print basis
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    plt.plot(x, b)
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    print b
    plt.plot(x, b)
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
from numpy.polynomial.chebyshev import chebval
h0 = chebval(x, [1, 0, 0])
h1 = chebval(x, [0, 1, 0])
h2 = chebval(x, [0, 0, 1])/10
plt.plot(x, h0)
plt.plot(x, h1)
plt.plot(x, h2)
gh0 = gaussian(x) * h0
gh1 = gaussian(x) * h1
gh2 = gaussian(x) * h2
plt.plot(x, gh0)
plt.plot(x, gh1)
plt.plot(x, gh2)
x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
from numpy.polynomial.chebyshev import chebval
h0 = chebval(x, [1, 0, 0])
h1 = chebval(x, [0, 1, 0])
h2 = chebval(x, [0, 0, 1])/10
h2 = chebval(x, [0, 0, 0, 1])/10
plt.plot(x, h0)
plt.plot(x, h1)
plt.plot(x, h2)
x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
from numpy.polynomial.chebyshev import chebval
h0 = chebval(x, [1, 0, 0])
h1 = chebval(x, [0, 1, 0])
h2 = chebval(x, [0, 0, 1])/10
h3 = chebval(x, [0, 0, 0, 1])/10
plt.plot(x, h0)
plt.plot(x, h1)
plt.plot(x, h2)
plt.plot(x, h3)
x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
from numpy.polynomial.chebyshev import chebval
h0 = chebval(x, [1, 0, 0])
h1 = chebval(x, [0, 1, 0])
h2 = chebval(x, [0, 0, 1])/10
h3 = chebval(x, [0, 0, 0, 1])/100
plt.plot(x, h0)
plt.plot(x, h1)
plt.plot(x, h2)
plt.plot(x, h3)
gh0 = gaussian(x) * h0
gh1 = gaussian(x) * h1
gh2 = gaussian(x) * h2
gh3 = gaussian(x) * h3
plt.plot(x, gh0)
plt.plot(x, gh1)
plt.plot(x, gh2)
plt.plot(x, gh3)
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    ch -= ch.min()
    ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    print b
    plt.plot(x, b)
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    print ch.min(),ch.max()
    ch -= ch.min()
    print ch.min(),ch.max()
    ch /= ch.max()
    print ch.min(),ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    print b
    plt.plot(x, b)
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    if ord > 0:
        ch -= ch.min()
    ch /= ch.max()
    print ch.min(),ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    print b
    plt.plot(x, b)
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    print b
    plt.plot(x, b)
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    #print b
    plt.plot(x, b)
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print pars; print basis
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])

for b in basis.T:
    #print b
    plt.plot(x, b)
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') - im1 for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print pars; print basis
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
print pars; print basis
print (pars[:basis.shape[1]] * basis).shape
print x.shape
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.02, 0.06), 15*gaussian(np.linspace(-0.02, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.02, 0.06), gaussian(np.linspace(-0.02, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.02, 0.06), gaussian(np.linspace(-0.02, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t #- 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
#source_x_t = np.array([-2.0, 2.0, -8.0, 8.0])
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources) # np.array([2., 7., 4., 13.]) * 2.
source_flux_s = source_flux_t # np.array([3., 7., 4., 13.]) * 2.  # fluxes of sources in science im
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.1  # make the source closest to x=0 have a small change in flux
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t  # fluxes of sources in science im
print source_x_t[np.argmin(np.abs(source_x_t))]
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.1  # make the source closest to x=0 have a small change in flux
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t  # fluxes of sources in science im
print source_x_t[np.argmin(np.abs(source_x_t))]
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.1  # make the source closest to x=0 have a small change in flux
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t  # fluxes of sources in science im
print source_x_t[np.argmin(np.abs(source_x_t))]
source_flux_s[np.argmin(np.abs(source_x_t))] *= 2.  # make the source closest to x=0 have a small change in flux
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t  # fluxes of sources in science im
print source_x_t[np.argmin(np.abs(source_x_t))]
source_flux_s[np.argmin(np.abs(source_x_t))] *= 2.  # make the source closest to x=0 have a small change in flux
print source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 2.  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.1  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=40)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 5*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 5*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 5*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 5*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 4*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 4*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.01  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 4*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 4*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.02  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 4*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 4*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
from numpy.polynomial.chebyshev import chebval

if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.025  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
from numpy.polynomial.chebyshev import chebval

# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
spatialKernelOrder = 0  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 0  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
## Compute the "L(ZOGY)" post-conv. kernel from kfit
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.025  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.02  # variance of template
sig2 = 0.02  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print pars-pars_old

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print (pars-pars_old)/pars

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print np.log10((pars-pars_old)/pars)

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print np.log10(np.abs(pars-pars_old)/pars)

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.025  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.1  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

plt.plot(np.linspace(df.min(), df.max()), 2*gaussian(np.linspace(df.min(), df.max()), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

print df.min()
plt.plot(np.linspace(df.min(), df.max()), 2*gaussian(np.linspace(df.min(), df.max()), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

print 'HERE:', df.min()
plt.plot(np.linspace(df.min(), df.max()), 2*gaussian(np.linspace(df.min(), df.max()), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

print 'HERE:', df.min()[0]
plt.plot(np.linspace(df.min(), df.max()), 2*gaussian(np.linspace(df.min(), df.max()), s=tmp1a.std()), color='r')
plt.plot(np.linspace(-0.06, 0.06), 2*gaussian(np.linspace(-0.06, 0.06), s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

print 'HERE:', df.min()[0]
xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 2*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 2*gaussian(xaxs, s=tmp2a.std()), color='b')
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp2a.std()), color='b')
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.1  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-400, 400, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.5  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-4000, 4000, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
source_flux_s[np.argmin(np.abs(source_x_t))] *= 1.5  # make the source closest to x=0 have a small change in flux
print source_x_t[np.argmin(np.abs(source_x_t))], source_flux_t[np.argmin(np.abs(source_x_t))], source_flux_s[np.argmin(np.abs(source_x_t))]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(-50, 50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 10*gaussian(xaxs, s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
#plt.xlim(-20, 20)
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp2a.std()), color='b')
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-4000, 4000, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.02   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
x_changed = np.argmin(np.abs(source_x_t))
source_flux_s[x_changed] *= 1.5  # make the source closest to x=0 have a small change in flux
print x_changed, source_x_t[x_changed], source_flux_t[x_changed], source_flux_s[x_changed]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(x_changed-50, x_changed+50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(x_changed-50, x_changed+50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
plt.xlim(x_changed-200, x_changed+200)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-4000, 4000, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.2   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
x_changed = np.argmin(np.abs(source_x_t))
source_flux_s[x_changed] *= 1.5  # make the source closest to x=0 have a small change in flux
print x_changed, source_x_t[x_changed], source_flux_t[x_changed], source_flux_s[x_changed]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(x_changed-50, x_changed+50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(x_changed-50, x_changed+50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
plt.xlim(x_changed-200, x_changed+200)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(xim[x_changed]-50, xim[x_changed]+50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
xim = np.arange(-4000, 4000, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.2   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
x_changed = np.argmin(np.abs(source_x_t))
source_flux_s[x_changed] *= 1.5  # make the source closest to x=0 have a small change in flux
print xim[x_changed], source_x_t[x_changed], source_flux_t[x_changed], source_flux_s[x_changed]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
xim = np.arange(-4000, 4000, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.2   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
x_changed = np.argmin(np.abs(source_x_t))
source_flux_s[x_changed] *= 1.5  # make the source closest to x=0 have a small change in flux
print source_x_t[x_changed], source_x_t[x_changed], source_flux_t[x_changed], source_flux_s[x_changed]
x_changed = source_x_t[x_changed]
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(xim[x_changed]-50, xim[x_changed]+50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
xim = np.arange(-4000, 4000, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.2   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
x_changed = np.argmin(np.abs(source_x_t))
source_flux_s[x_changed] *= 1.5  # make the source closest to x=0 have a small change in flux
print source_x_t[x_changed], source_x_t[x_changed], source_flux_t[x_changed], source_flux_s[x_changed]
xcen = int(source_x_t[x_changed])
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(xcen-50, xcen+50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(xcen-150, xcen+150)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(xcen-50, xcen+50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
plt.xlim(xcen-200, xcen+200)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
plt.rcParams['figure.figsize'] = (14.0, 4.0)

np.random.seed(66)
from numpy.polynomial.chebyshev import chebval
from scipy.fftpack import fft, ifft, fftfreq
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
def gaussian_ft(x, m=0., s=1.0):
    kp = gaussian(x, m, s)
    FFT = fft(kp)
    return FFT
# post_conv_kernel = sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
def post_conv_kernel_ft(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = gaussian_ft(x, m, sigk)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(x, sig1=1., sig2=1., m=0., sigk=1.):
    kft = post_conv_kernel_ft(x, sig1, sig2, m, sigk)
    out = ifft(kft)
    return out
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, sig1=1., sig2=1., m=0., sigk=1., psfsig1=1.):
    kft = gaussian_ft(x, m, sigk)
    sig1ft = gaussian_ft(x, m, psfsig1)
    return sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_psf(x, sig1=1., sig2=1., m=0., sigk=1., psfsig=1.):
    kft = post_conv_psf_ft(x, sig1, sig2, m, sigk, psfsig)
    out = ifft(kft)
    return out
def chebBasis(x, ord):
    coef = np.zeros(ord+1)
    coef[-1] = 1
    ch = chebval(x, coef)
    return ch, coef

def chebGauss(x, m=0., s=1., ord=0, beta=1.):
    ga = gaussian(x, m, s/beta)
    ch, coef = chebBasis(x, ord)
    #if ord > 0:  # best not to "fix" the basis funcs.
    #    ch -= ch.min()
    #ch /= ch.max()
    print s, ord, coef #, sum(ga), sum(ch), sum(ga*ch)
    out = ga * ch
    return out
if False:
    x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
    h0 = chebval(x, [1, 0, 0])
    h1 = chebval(x, [0, 1, 0])
    h2 = chebval(x, [0, 0, 1])/10
    h3 = chebval(x, [0, 0, 0, 1])/100
    plt.plot(x, h0)
    plt.plot(x, h1)
    plt.plot(x, h2)
    plt.plot(x, h3)
    
if False:
    gh0 = gaussian(x) * h0
    gh1 = gaussian(x) * h1
    gh2 = gaussian(x) * h2
    gh3 = gaussian(x) * h3
    plt.plot(x, gh0)
    plt.plot(x, gh1)
    plt.plot(x, gh2)
    plt.plot(x, gh3)
xim = np.arange(-4000, 4000, 1.0)  # assume image coords are centered on sources
n_sources = 50
psf1 = 1.6 # sigma in pixels im1 will be template
psf2 = 2.2 # sigma in pixels im2 will be science image
source_x_t = np.random.uniform(xim.min(), xim.max(), size=n_sources)
source_x_s = source_x_t - 0.2   # add an offset?
source_flux_t = np.random.uniform(0, 30, size=n_sources)
source_flux_s = source_flux_t.copy()  # fluxes of sources in science im
x_changed = np.argmin(np.abs(source_x_t))
source_flux_s[x_changed] *= 1.5  # make the source closest to x=0 have a small change in flux
print source_x_t[x_changed], source_x_t[x_changed], source_flux_t[x_changed], source_flux_s[x_changed]
xcen = int(source_x_t[x_changed])
im1 = np.zeros(len(xim))
im2 = im1.copy()
for i, cen in enumerate(source_x_t):
    source = gaussian(xim, m=cen, s=psf1)
    im1 += source_flux_t[i] * source / source.sum()
    source = gaussian(xim, m=source_x_s[i], s=psf2)
    im2 += source_flux_s[i] * source / source.sum()
sig1 = 0.2  # variance of template
sig2 = 0.2  # variance of science image
im1_noise = np.random.normal(scale=sig1, size=len(im1))
im2_noise = np.random.normal(scale=sig2, size=len(im2))
im1 += im1_noise
im2 += im2_noise
print im1.sum(), im2.sum()
plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2-im1)
if False:
    im2_psf = gaussian(x, s=psf2)
    im2_psf /= im2_psf.sum()
    im2_preconv = np.convolve(im2, im2_psf, mode='same')
    print im2.sum(), im2_preconv.sum()
    plt.plot(xim, im1); plt.plot(xim, im2); plt.plot(xim, im2_preconv); plt.plot(xim, im2-im1)

## Don't pre-convolve?
im2_preconv = im2
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 1.   # in the Becker et al. paper sigGauss is 1 and LSST PSF is around 2 pixels?
spatialKernelOrder = 2  # 2  # polynomial for modifying the shape of the kernel across the image
spatialBackgroundOrder = 1  # 1  # polynomial for adding background gradient to fit
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

x = np.arange(-9, 10, 1.)  # This is the axis that we will compute the conv. kernels on
basis = [chebGauss(x, m=0, s=sig, ord=deg, beta=betaGauss) \
         for i,sig in enumerate(sigGauss) for deg in range(degGauss[i])] #, kernelOrd=ko) for ko in range(spatialKernelOrder+1)]
basis = np.vstack(basis).T  # put the bases into columns

for b in basis.T:
    #print b
    plt.plot(x, b)

# Single call to do it with all bases
# First use the original (non spatially modified) basis
basis2 = [np.convolve(im1, b, mode='same') for b in basis.T]
basis2 = np.vstack(basis2).T

# Then make the spatially modified basis by simply multiplying the constant
#  basis (basis2 from above) by a polynomial along the image coordinate.
# Note that since we are *not* including i=0, this *does not include* basis2.
if spatialKernelOrder > 0:
    xx = xim/np.max(np.abs(xim))
    basis2m = [b * xx**i for i in range(1, spatialKernelOrder+1) for b in basis2.T]
    basis2m = np.vstack(basis2m).T
    basis2 = np.hstack([basis2, basis2m])

# Then make the spatial background part
if spatialBackgroundOrder >= 0:
    bgBasis = [chebBasis(xim, ord)[0] for ord in range(spatialBackgroundOrder+1)]
    bgBasis = np.vstack(bgBasis).T
    basis2 = np.hstack([basis2, bgBasis])
#%timeit np.linalg.lstsq(basis2, im2_preconv)
pars_old, resid, _, _ = np.linalg.lstsq(basis2, im2_preconv)
print pars_old
#%%timeit 
#basis2 /= basis2.sum(0)
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
b = np.dot(basis2.T, im2_preconv) #(basis2.T * im2_preconv).sum(1)
M = np.dot(basis2.T, basis2)
pars, resid, _, _ = np.linalg.lstsq(M, b)
print pars
print 'Difference (log10):\n', np.log10(np.abs((pars-pars_old)/pars))

fit = (pars * basis2).sum(1)
print basis2.shape, fit.shape, pars.shape
#plt.plot(x, im2 - fit)  # science - convolved template (red)
#plt.plot(x, im2 - im1)  # science - original template (blue)
plt.rcParams['figure.figsize'] = (12.0, 4.0)
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, fit)  # convolved template (blue)  -- note looks purple because it's right on top of im2
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # preconvolved science image (dotted, purple)
ax1.plot(xim, im2_preconv - fit)  # diffim (grey)

ax2.plot(xim, im2_preconv - fit)
plt.xlim(xcen-50, xcen+50)
plt.show()

print np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
kfit = (pars[:basis.shape[1]] * basis).sum(1)
print kfit.sum()
kfit /= kfit.sum()
plt.plot(x, kfit)  # this plots the matching kernel
conv_im1 = np.convolve(im1, kfit, mode='same')
f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)
ax1.plot(xim, im1)  # original template (red)
ax1.plot(xim, conv_im1)  # convolved template (blue)
ax1.plot(xim, im2_preconv, ls='-.', lw=3)  # science image (dotted, purple)
ax1.plot(xim, im2_preconv - conv_im1)  # diffim (grey)

ax2.plot(xim, im2_preconv - conv_im1)  # diffim
plt.xlim(xcen-50, xcen+50)
plt.show()

print np.sum((im2_preconv-conv_im1)**2), np.sum((im2_preconv-fit)**2), np.sum((im2-im1)**2)
def kernel_ft(kernel):
    kp = kernel
    FFT = fft(kp)
    return FFT
def post_conv_kernel_ft(kernel, sig1=1., sig2=1.):
    kft = kernel_ft(kernel)
    return np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
def post_conv_kernel(kernel, sig1=1., sig2=1.):
    kft = post_conv_kernel_ft(kernel, sig1, sig2)
    out = ifft(kft)
    return out

pck = post_conv_kernel(kfit, sig1=sig2, sig2=sig1)
print pck.real.max()
print pck.real.min()
print pck.real.sum()
plt.plot(x, np.fft.ifftshift(pck.real))
plt.ylim(np.min(pck.real), np.abs(np.min(pck.real))) #; plt.xlim(-2, 2)
pck = np.fft.ifftshift(pck.real)
print pck.sum(), pck.max(), pck.min()
#pck /= pck.sum()
pci = np.convolve(im2_preconv-conv_im1, pck, mode='same')
plt.plot(xim, pci)  # red - corrected diffim
plt.plot(xim, im2_preconv-conv_im1)  # blue - original diffim
import pandas as pd
df = pd.DataFrame({'corr': pci, 'orig': im2_preconv-conv_im1})
df.plot.hist(alpha=0.5, bins=40)
print 'Corrected:', np.mean(pci), np.std(pci)
print 'Original: ', np.mean(im2_preconv-conv_im1), np.std(im2_preconv-conv_im1)
print 'Expected: ', np.sqrt(sig1**2 + sig2**2)
# post_conv_psf = phi_1(k) * sym.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kappa_ft(k)**2))
# we'll parameterize phi_1(k) as a gaussian with sigma "psfsig1".
def post_conv_psf_ft(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = kernel_ft(kernel)
    sig1ft = gaussian_ft(x, s=psfsig1)
    out = sig1ft * np.sqrt((sig1**2 + sig2**2) / (sig1**2 + sig2**2 * kft**2))
    return out
def post_conv_psf(x, kernel, sig1=1., sig2=1., psfsig1=1.):
    kft = post_conv_psf_ft(x, kernel, sig1, sig2, psfsig1)
    out = ifft(kft)
    return out

pcf = post_conv_psf(x, kernel=kfit, sig1=sig2, sig2=sig1, psfsig1=psf2)  # psfsig is sigma of psf of im2 (science image)
pcf = pcf.real / pcf.real.sum()
plt.plot(x, pcf)  # red - corrected PSF
phi2 = gaussian(x, s=psf2) * (x[1]-x[0]) ## compare to phi_1(x)
plt.plot(x, phi2)  # blue - original PSF
tmp1 = np.convolve(pci, pcf, mode='same')
plt.plot(xim, tmp1)  # red - corrected
tmp2 = np.convolve(im2_preconv-conv_im1, phi2, mode='same')
plt.plot(xim, tmp2)  # blue - original
df = pd.DataFrame({'corr': tmp1, 'orig': tmp2})
df.plot.hist(alpha=0.5, bins=50)

print tmp1.std()*5., tmp2.std()*5.
print np.sum(np.abs(tmp1) > tmp1.std()*5.), np.sum(np.abs(tmp2) > tmp2.std()*5.)

import scipy.stats
tmp1a, low, upp = scipy.stats.sigmaclip(tmp1)
tmp2a, low, upp = scipy.stats.sigmaclip(tmp2)
print tmp1a.std()*5., tmp2a.std()*5.

det1 = xim[np.abs(tmp1) > tmp1a.std()*5.]
det2 = xim[np.abs(tmp2) > tmp2a.std()*5.]
print '1:', len(det1)
if len(det1) > 0: 
    print det1.min(), det1.max()
print '2:', len(det2)
if len(det2) > 0:
    print det2.min(), det2.max()

xaxs = np.linspace(df.min()[0], df.max()[0])
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp1a.std()), color='r')
plt.plot(xaxs, 100*gaussian(xaxs, s=tmp2a.std()), color='b')
plt.plot(xim, tmp1)  # red - corrected
plt.plot(det1, np.repeat(tmp1.max(), len(det1)), '|', color='r')
plt.plot([xim.min(), xim.max()], np.repeat(tmp1a.std()*5., 2), color='r')
plt.plot(xim, tmp2)  # blue - original
plt.plot(det2, np.repeat(tmp2.max(), len(det2)), '|', color='b')
plt.plot([xim.min(), xim.max()], np.repeat(tmp2a.std()*5., 2), color='b')
plt.xlim(xcen-200, xcen+200)
import numpy as np
%matplotlib inline
import matplotlib.pyplot as plt
import matplotlib
matplotlib.style.use('ggplot')
import pandas as pd
def gaussian(x, m=0., s=1.0):
    out = 1/(s*np.sqrt(2*np.pi))*np.exp(-(x-m)**2./(2.*s**2.))
    return out / out.sum() / (x[1] - x[0])
from scipy.stats import multivariate_normal

## see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html

def gaussian2d(grid, m=None, s=None):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    var = multivariate_normal(mean=m, cov=cov)
    return var.pdf(grid)

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
g1 = gaussian2d(grid) + gaussian2d(grid, [10,5], [3,1])
plt.imshow(g1)
from numpy.polynomial.chebyshev import chebgrid2d
h0 = chebgrid2d(x, y, c=[[0,1],[0,1]])
from numpy.polynomial.chebyshev import chebgrid2d
h0 = chebgrid2d(x, y, c=[[0,1],[0,1]])
print h0.shape
plt.imshow(h0)
from numpy.polynomial.chebyshev import chebgrid2d
h0 = chebgrid2d(x, y, c=[0,1])
print h0.shape
plt.imshow(h0)
from numpy.polynomial.chebyshev import chebgrid2d
x = np.arange(-15, 16, 1)
y = x.copy()
h0 = chebgrid2d(x, y, c=[[0,1],[0,1]])
print h0.shape
plt.imshow(h0)
## TBD: use chebgrid2d:
## http://students.mimuw.edu.pl/~pbechler/numpy_doc/reference/generated/numpy.polynomial.chebyshev.chebgrid2d.html

x = np.arange(-15, 16, 1)
y = x.copy()

#h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
h0 = chebval2d(x, y, [0, 1, 0], [0, 1, 0])
#h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
#h0 = chebval2d(x, y, [0, 1, 0], [0, 0, 1])
print h0.shape
plt.imshow(h0)
from numpy.polynomial.chebyshev import chebval
def chebval2d(x, y, xord, yord):
    cx = chebval(x, xord)
    cy = chebval(y, yord)
    h0 = np.outer(cx, cy)
    return h0
## TBD: use chebgrid2d:
## http://students.mimuw.edu.pl/~pbechler/numpy_doc/reference/generated/numpy.polynomial.chebyshev.chebgrid2d.html

x = np.arange(-15, 16, 1)
y = x.copy()

#h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
h0 = chebval2d(x, y, [0, 1, 0], [0, 1, 0])
#h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
#h0 = chebval2d(x, y, [0, 1, 0], [0, 0, 1])
print h0.shape
plt.imshow(h0)
## The following code does exactly the same as the above:
from numpy.polynomial.chebyshev import chebval
def chebval2d(x, y, xord, yord):
    cx = chebval(x, xord)
    cy = chebval(y, yord)
    h0 = np.outer(cx, cy)
    return h0

if False:
    #h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
    h0 = chebval2d(x, y, [0, 1, 0], [0, 1, 0])
    #h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
    #h0 = chebval2d(x, y, [0, 1, 0], [0, 0, 1])
    print h0.shape
    plt.imshow(h0)
gh0 = gaussian2d(grid, s=[3., 3.]) * h0
#gh1 = gaussian(x) * h1
#gh2 = gaussian(x) * h2
plt.imshow(gh0)
#plt.plot(x, gh1)
#plt.plot(x, gh2)
from numpy.polynomial.chebyshev import chebgrid2d
x = np.arange(-15, 16, 1)
y = x.copy()
#h0 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
h0 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 1, 0]])
#h0 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
#h0 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 0, 1]])
plt.imshow(h0)
from mpl_toolkits.axes_grid1 import ImageGrid
from numpy.polynomial.chebyshev import chebgrid2d
x = np.arange(-15, 16, 1)
y = x.copy()
h0 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
h1 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 1, 0]])
h2 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
h3 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 0, 1]])
from mpl_toolkits.axes_grid1 import ImageGrid
grid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
grid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
grid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
grid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
grid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
grid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
grid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
grid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
grid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
grid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
from numpy.polynomial.chebyshev import chebgrid2d
x = np.arange(-15, 16, 1)
y = x.copy()
h0 = chebgrid2d(x, y, c=[[1, 0, 0], [1, 0, 0]])
h1 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 1, 0]])
h2 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
h3 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 0, 1]])
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
grid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
grid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
grid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
grid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
grid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
grid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
grid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
grid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
grid[2].imshow(h0)  # The AxesGrid object work as a list of axes.
grid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
grid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
grid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
grid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
grid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
grid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
## The following code does exactly the same as the above:
from numpy.polynomial.chebyshev import chebval
def chebval2d(x, y, xord, yord):
    cx = chebval(x, xord)
    cy = chebval(y, yord)
    h0 = np.outer(cx, cy)
    return h0

if False:
    #h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
    h0 = chebval2d(x, y, [0, 1, 0], [0, 1, 0])
    #h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
    #h0 = chebval2d(x, y, [0, 1, 0], [0, 0, 1])
    print h0.shape
    plt.imshow(h0)
gh0 = gaussian2d(grid, s=[3., 3.]) * h0
gh0 = gaussian2d(grid, s=[3., 3.]) * h1
gh0 = gaussian2d(grid, s=[3., 3.]) * h2
gh0 = gaussian2d(grid, s=[3., 3.]) * h3
fig = plt.figure(1, (4., 4.))
grid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
grid[0].imshow(gh0)  # The AxesGrid object work as a list of axes.
grid[1].imshow(gh1)  # The AxesGrid object work as a list of axes.
grid[2].imshow(gh2)  # The AxesGrid object work as a list of axes.
grid[3].imshow(gh3)  # The AxesGrid object work as a list of axes.
from scipy.stats import multivariate_normal

## see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html

def gaussian2d(grid, m=None, s=None):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    var = multivariate_normal(mean=m, cov=cov)
    return var.pdf(grid)

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
g1 = gaussian2d(grid) + gaussian2d(grid, [10,5], [3,1])
plt.imshow(g1)
from numpy.polynomial.chebyshev import chebgrid2d
x = np.arange(-15, 16, 1)
y = x.copy()
h0 = chebgrid2d(x, y, c=[[1, 0, 0], [1, 0, 0]])
h1 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 1, 0]])
h2 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
h3 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 0, 1]])
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
gh0 = gaussian2d(grid, s=[3., 3.]) * h0
gh0 = gaussian2d(grid, s=[3., 3.]) * h1
gh0 = gaussian2d(grid, s=[3., 3.]) * h2
gh0 = gaussian2d(grid, s=[3., 3.]) * h3
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(gh0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(gh1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(gh2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(gh3)  # The AxesGrid object work as a list of axes.
gh0 = gaussian2d(grid, s=[3., 3.]) * h0
gh1 = gaussian2d(grid, s=[3., 3.]) * h1
gh2 = gaussian2d(grid, s=[3., 3.]) * h2
gh3 = gaussian2d(grid, s=[3., 3.]) * h3
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(gh0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(gh1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(gh2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(gh3)  # The AxesGrid object work as a list of axes.
x = np.arange(-15, 16, 1)
y = x.copy()
print grid
x = np.arange(-15, 16, 1)
y = x.copy()

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
print x
x = np.arange(-15, 16, 1)
y = x.copy()
print np.meshgrid(x, y)

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
print x
x = np.arange(-15, 16, 1)
y = x.copy()
x, y = np.meshgrid(x, y)
print x

#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
#print x
x = np.arange(-15, 16, 1)
y = x.copy()
x0, y = np.meshgrid(x, y)
#print x

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
print x-x0
x = np.arange(-15, 16, 1)
y = x.copy()
x0, y = np.meshgrid(x, y)
print x

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
print x
x = np.arange(-15, 16, 1)
y = x.copy()
x0, y = np.meshgrid(x, y)
print x0

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
print x
x = np.arange(-15, 16, 1)
y = x.copy()
x0, y0 = np.meshgrid(x, y)
print y0

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
print x
x = np.arange(-15, 16, 1)
y = x.copy()
x0, y0 = np.meshgrid(x, y)
#print y0

x, y = np.mgrid[-15:16:1, -15:16:1]
grid = np.dstack((x, y))
print x-y0
x = np.arange(-15, 16, 1)
y = x.copy()
x0, y0 = np.meshgrid(x, y)
grid = np.dstack((y0, x0))
#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
#print x-y0
from scipy.stats import multivariate_normal

## see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html

def gaussian2d(grid, m=None, s=None):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    var = multivariate_normal(mean=m, cov=cov)
    return var.pdf(grid)

#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
g1 = gaussian2d(grid) + gaussian2d(grid, [10,5], [3,1])
plt.imshow(g1)
from numpy.polynomial.chebyshev import chebgrid2d

h0 = chebgrid2d(x, y, c=[[1, 0, 0], [1, 0, 0]])
h1 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 1, 0]])
h2 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
h3 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 0, 1]])
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
## The following code does exactly the same as the above:
from numpy.polynomial.chebyshev import chebval
def chebval2d(x, y, xord, yord):
    cx = chebval(x, xord)
    cy = chebval(y, yord)
    h0 = np.outer(cx, cy)
    return h0

if False:
    #h0 = chebval2d(x, y, [1, 0, 0], [0, 1, 0])
    h0 = chebval2d(x, y, [0, 1, 0], [0, 1, 0])
    #h0 = chebval2d(x, y, [0, 1, 0], [0, 0, 1])
    print h0.shape
    plt.imshow(h0)
gh0 = gaussian2d(grid, s=[3., 3.]) * h0
gh1 = gaussian2d(grid, s=[3., 3.]) * h1
gh2 = gaussian2d(grid, s=[3., 3.]) * h2
gh3 = gaussian2d(grid, s=[3., 3.]) * h3
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(gh0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(gh1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(gh2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(gh3)  # The AxesGrid object work as a list of axes.
from numpy.polynomial.chebyshev import chebval2d
from numpy.polynomial.chebyshev import chebval2d
chebval2d(x0, y0, c=[[1, 0, 0], [1, 0, 0]])
from numpy.polynomial.chebyshev import chebval2d
h0 = chebval2d(x0, y0, c=[[1, 0, 0], [1, 0, 0]])
from numpy.polynomial.chebyshev import chebval2d
h0 = chebval2d(x0, y0, c=[[1, 0, 0], [1, 0, 0]])
plt.imshow(h0)
x = np.arange(-15, 16, 1)
y = x.copy()
y0, x0 = np.meshgrid(x, y)
grid = np.dstack((x0, y0))
#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
#print x-y0
from scipy.stats import multivariate_normal

## see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html

def gaussian2d(grid, m=None, s=None):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    var = multivariate_normal(mean=m, cov=cov)
    return var.pdf(grid)

#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
g1 = gaussian2d(grid) + gaussian2d(grid, [10,5], [3,1])
plt.imshow(g1)
from scipy.stats import multivariate_normal

## see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html

def gaussian2d(grid, m=None, s=None):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    var = multivariate_normal(mean=m, cov=cov)
    return var.pdf(grid)

#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
g1 = gaussian2d(grid) + gaussian2d(grid, [5,5], [3,1])
plt.imshow(g1)
x = np.arange(-15, 16, 1)
y = x.copy()
y0, x0 = np.meshgrid(x, y)
grid = np.dstack((y0, x0))
#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
#print x-y0
from scipy.stats import multivariate_normal

## see https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html

def gaussian2d(grid, m=None, s=None):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    var = multivariate_normal(mean=m, cov=cov)
    return var.pdf(grid)

#x, y = np.mgrid[-15:16:1, -15:16:1]
#grid = np.dstack((x, y))
g1 = gaussian2d(grid) + gaussian2d(grid, [5,5], [3,1])
plt.imshow(g1)
from numpy.polynomial.chebyshev import chebval2d
h0 = chebval2d(x0, y0, c=[[1, 0, 0], [1, 0, 0]])
plt.imshow(h0)
from numpy.polynomial.chebyshev import chebgrid2d

h0 = chebgrid2d(x, y, c=[[1, 0, 0], [1, 0, 0]])
h1 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 1, 0]])
h2 = chebgrid2d(x, y, c=[[1, 0, 0], [0, 1, 0]])
h3 = chebgrid2d(x, y, c=[[0, 1, 0], [0, 0, 1]])
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
from numpy.polynomial.chebyshev import chebval2d
h0 = chebval2d(x0, y0, c=[[1, 0, 0], [1, 0, 0]])
#plt.imshow(h0)
h0 = chebval2d(x0, y0, c=[[1, 0, 0], [1, 0, 0]])
h1 = chebval2d(x0, y0, c=[[0, 1, 0], [0, 1, 0]])
h2 = chebval2d(x0, y0, c=[[1, 0, 0], [0, 1, 0]])
h3 = chebval2d(x0, y0, c=[[0, 1, 0], [0, 0, 1]])
from mpl_toolkits.axes_grid1 import ImageGrid
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(h0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(h1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(h2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(h3)  # The AxesGrid object work as a list of axes.
gh0 = gaussian2d(grid, s=[3., 3.]) * h0
gh1 = gaussian2d(grid, s=[3., 3.]) * h1
gh2 = gaussian2d(grid, s=[3., 3.]) * h2
gh3 = gaussian2d(grid, s=[3., 3.]) * h3
fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes
                 axes_pad=0.1,  # pad between axes in inch.
                 )
igrid[0].imshow(gh0)  # The AxesGrid object work as a list of axes.
igrid[1].imshow(gh1)  # The AxesGrid object work as a list of axes.
igrid[2].imshow(gh2)  # The AxesGrid object work as a list of axes.
igrid[3].imshow(gh3)  # The AxesGrid object work as a list of axes.
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    ga = gaussian2d(grid, m, s/beta)
    coef0 = np.zeros(ord[0]+1)
    coef0[-1] = 1
    coef1 = np.zeros(ord[1]+1)
    coef1[-1] = 1
    print s, ord, coef0, coef1
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x, y, grid, m=0, s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
basis = [chebGauss2d(x, y, grid, m=0[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
basis = [chebGauss2d(x, y, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    ga = gaussian2d(grid, m, np.array(s)/beta)
    coef0 = np.zeros(ord[0]+1)
    coef0[-1] = 1
    coef1 = np.zeros(ord[1]+1)
    coef1[-1] = 1
    print s, ord, coef0, coef1
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x, y, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    coef0 = np.zeros(ord[0]+1)
    coef0[-1] = 1
    coef1 = np.zeros(ord[1]+1)
    coef1[-1] = 1
    print s, ord, coef0, coef1
    ga = gaussian2d(grid, m, np.array(s)/beta)
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
ord=[[0,1],[0,0,1]]
ord=[[0,1],[0,0,1]]
ord.shape
ord=[[0,1],[0,0,1]]
np.array(ord).shape
ord=[[0,1],[0,0,1]]
np.max([len(ord[0]), len(ord1[1])])
ord=[[0,1],[0,0,1]]
np.max([len(ord[0]), len(ord[1])])
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    coefLen = np.max([len(ord[0]), len(ord1)])
    coef0 = np.zeros(coefLen+1)
    coef0[ord[0]] = 1
    coef1 = np.zeros(coefLen+1)
    coef1[ord[1]] = 1
    print s, ord, coef0, coef1
    ga = gaussian2d(grid, m, np.array(s)/beta)
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    coefLen = np.max([len(ord[0]), len(ord[1])])
    coef0 = np.zeros(coefLen+1)
    coef0[ord[0]] = 1
    coef1 = np.zeros(coefLen+1)
    coef1[ord[1]] = 1
    print s, ord, coef0, coef1
    ga = gaussian2d(grid, m, np.array(s)/beta)
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    coefLen = np.max([ord[0], ord[1]])
    coef0 = np.zeros(coefLen+1)
    coef0[ord[0]] = 1
    coef1 = np.zeros(coefLen+1)
    coef1[ord[1]] = 1
    print s, ord, coef0, coef1
    ga = gaussian2d(grid, m, np.array(s)/beta)
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    coefLen = np.max([ord[0], ord[1]])
    coef0 = np.zeros(coefLen+1)
    coef0[ord[0]] = 1
    coef1 = np.zeros(coefLen+1)
    coef1[ord[1]] = 1
    print s, ord, coef0, coef1
    ga = gaussian2d(grid, m, np.array(s)/beta)
    ch = chebval2d(x, y, c=[coef0, coef1])
    print ga.shape, ch.shape, (ga*ch).shape
    return ga * ch
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1.):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    coefLen = np.max([ord[0], ord[1]])
    coef0 = np.zeros(coefLen+1)
    coef0[ord[0]] = 1
    coef1 = np.zeros(coefLen+1)
    coef1[ord[1]] = 1
    print s, ord, coef0, coef1
    ga = gaussian2d(grid, m, np.array(s)/beta)
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
for b in basis.T:
    plt.plot(x, b)
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis)  # put the bases into columns
print basis.shape
# basis = pd.DataFrame(basis); basis.plot()
#for b in basis.T:
#    plt.plot(x, b)
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
    
# igrid = ImageGrid(fig, 111,  # similar to subplot(111)
#                  nrows_ncols=(2, 2),  # creates 2x2 grid of axes
#                  axes_pad=0.1,  # pad between axes in inch.
#                  )
# igrid[0].imshow(gh0)  # The AxesGrid object work as a list of axes.
# igrid[1].imshow(gh1)  # The AxesGrid object work as a list of axes.
# igrid[2].imshow(gh2)  # The AxesGrid object work as a list of axes.
# igrid[3].imshow(gh3)  # The AxesGrid object work as a list of axes.
print basis.shape, basis[0].shape
basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
    
# igrid = ImageGrid(fig, 111,  # similar to subplot(111)
#                  nrows_ncols=(2, 2),  # creates 2x2 grid of axes
#                  axes_pad=0.1,  # pad between axes in inch.
#                  )
# igrid[0].imshow(gh0)  # The AxesGrid object work as a list of axes.
# igrid[1].imshow(gh1)  # The AxesGrid object work as a list of axes.
# igrid[2].imshow(gh2)  # The AxesGrid object work as a list of axes.
# igrid[3].imshow(gh3)  # The AxesGrid object work as a list of axes.
print basis.shape, basis[0].shape, basis[0].reshape(x0.shape)

igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis.shape, basis[0].shape, x0.shape #basis[0].reshape(x0.shape)

igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis.shape, basis[0].shape, x0.shape, 31*31 #basis[0].reshape(x0.shape)

igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis.shape, basis[0].shape, x0.shape, grid.shape, 31*31 #basis[0].reshape(x0.shape)

igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
print basis.shape, basis[0].shape, x0.shape, grid.shape, 31*31 #basis[0].reshape(x0.shape)

igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis[0].shape, x0.shape, grid.shape, 31*31 #basis[0].reshape(x0.shape)

igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis[0].shape, x0.shape, grid.shape

igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i])

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape)

fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape)

fig = plt.figure(1, (4., 4.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape).shape

fig = plt.figure(1, (8., 8.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape).shape

fig = plt.figure(1, (16., 16.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis[0].shape, x0.shape, grid.shape#, basis[0].reshape(x0.shape).shape

fig = plt.figure(1, (16., 16.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape).shape

fig = plt.figure(1, (16., 16.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape).shape

fig = plt.figure(1, (16., 16.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))

basis = np.vstack(basis).T  # put the bases into columns
print basis.shape, basis[0].shape
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss, verbose=True) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape).shape

fig = plt.figure(1, (16., 16.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))
# Parameters from stack
sigGauss = [0.75, 1.5, 3.0]
degGauss = [4, 2, 2]
betaGauss = 2   # in the Becker et al. paper sigGauss is 1 but PSF is more like 2 pixels?
# Parameters from and Becker et al. (2012)
#sigGauss = [0.75, 1.5, 3.0]
#degGauss = [6, 4, 2]

def chebGauss2d(x, y, grid, m=None, s=None, ord=[0,0], beta=1., verbose=False):
    if m is None:
        m = [0., 0.]
    if s is None:
        s = [1., 1.]
    cov = [[s[0], 0], [0, s[1]]]
    coefLen = np.max([ord[0], ord[1]])
    coef0 = np.zeros(coefLen+1)
    coef0[ord[0]] = 1
    coef1 = np.zeros(coefLen+1)
    coef1[ord[1]] = 1
    if verbose:
        print s, ord, coef0, coef1
    ga = gaussian2d(grid, m, np.array(s)/beta)
    ch = chebval2d(x, y, c=[coef0, coef1])
    return ga * ch
basis = [chebGauss2d(x0, y0, grid, m=[0,0], s=[sig0,sig1], ord=[deg0,deg1], beta=betaGauss, verbose=True) for i0,sig0 in enumerate(sigGauss) for deg0 in range(degGauss[i0]) for i1,sig1 in enumerate(sigGauss) for deg1 in range(degGauss[i1])]
print basis[0].shape, x0.shape, grid.shape, basis[0].reshape(x0.shape).shape

fig = plt.figure(1, (16., 16.))
igrid = ImageGrid(fig, 111,  # similar to subplot(111)
                 nrows_ncols=(6, 6),  # creates 2x2 grid of axes
                 axes_pad=0.05,  # pad between axes in inch.
                 )
for i in range(32):
    igrid[i].imshow(basis[i].reshape(x0.shape))
from lsst.ip.diffim import DipoleFitTask
import lsst.afw.table as afwTable
import lsst.daf.persistence as dp
butler=dp.Butler('decamDirTest')
butler.get('deepDiff_diaSrc',visit='289820',ccdnum='11')
butler.get('deepDiff_diaSrc',visit=289820,ccdnum=11)
sources=butler.get('deepDiff_diaSrc',visit=289820,ccdnum=11)
sources[0]
sources[0].extract('ip_diffim_DipoleFit*')
sources[0].extract('ip_diffim_DipoleMeasurement*')
sources[0].extract('ip_diffim_PsfDipoleFlux*')
import lsst.daf.persistence as dp
sources=butler.get('deepDiff_diaSrc',visit=289820,ccdnum=11)
butler=dp.Butler('decamDirTest')
sources=butler.get('deepDiff_diaSrc',visit=289820,ccdnum=11)
sources[0].extract('ip_diffim_DipoleMeasurement*')
sources[0].extract('ip_diffim_DipoleFit*')
sources[0].extract('ip_diffim_Naive*')
import lsst.daf.persistence as dp
butler=dp.Butler('decamDirTest')
sources=butler.get('deepDiff_diaSrc',visit=289820,ccdnum=11)
sources[0].extract('ip_diffim_Naive*')
sources[0].extract('ip_diffim_Psfd*')
sources[0].extract('ip_diffim_Psf*')
sources[1].extract('ip_diffim_Psf*')
len(sources)
sources.get('ip_diffim_PsfDipoleFlux_centroid_x')
sources[0].extract('ip_diffim_DipoleFit*')
sources.get('ip_diffim_DipoleFit_centroid_x')
import pandas as pd
pd.DataFrame(sources)
sources.columns['ip_diffim_DipoleFit_pos_flux']

pd.DataFrame({col: sources.get(col) for col in sources.columns})
sources.columns[0]
sources.columns['ip_diffim_DipoleFit_pos_flux']
sources.columns
sources.schema
sources.schema.keys
sources.columns
sources.columns.names
sources.columns
keys(sources.columns)
sources.columns.
sources.schema
sources.schema.getNames()
pd.DataFrame({col: sources.columns[col] for col in sources.schema.getNames()})
history
import readline
readline.write_history_file('history.txt')
